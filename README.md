# Machine-Learning-HW

This is Machine learning HW in 2016 fall semester in NCTU. Teaching by prof.簡仁宗

Including
 - Baysian polynomial regression
 - Baysian linear regression
 - Cross validation
 - Dimension reduction by PCA, LDA
 - Classification by fisher criterion
 - Logistic regression
 - Gaussain process regression
 - Gaussain process classification
 - SVM classifiaction with linear and polynomial model

I don't know whether this homework is right or not, but the grade of each hw is 98, 92, and 100. Somehow it is good enough.

## About final exam
Due to no answer sheet, I just record what I remember.
 - Nadaraya derivation
 - Proof k(x1,x1) * k(x2,x2) >= k(x1,x2)^2 (by cauchy inequality)
 - Why we need EM algorithm
 - Gibbs sampling
 - EM algorithm derivation by KL divergence and illustrate the relationship between E-step and M-step
 - Continuous density HMM   
